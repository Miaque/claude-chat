import asyncio
import datetime
import json
from dataclasses import dataclass
from typing import Any, AsyncGenerator, Dict, Optional

from loguru import logger

from core.error_processor import ErrorProcessor
from core.prompts.prompt import get_system_prompt
from core.response_processor import ProcessorConfig
from core.services.db import get_db
from core.thread_manager import ThreadManager
from models.message import Message
from models.project import Project, ProjectModel
from models.thread import Thread


@dataclass
class AgentConfig:
    thread_id: str
    project_id: str
    native_max_auto_continues: int = 25
    max_iterations: int = 100
    model_name: str = "glm-4.6"
    agent_config: Optional[dict] = None


class PromptManager:
    @staticmethod
    async def build_system_prompt(
        model_name: str,
        agent_config: Optional[dict],
        thread_id: str,
        tool_registry=None,
        user_id: Optional[str] = None,
    ) -> dict:
        default_system_content = get_system_prompt()

        # ä»ä»£ç†çš„æ­£å¸¸ç³»ç»Ÿæç¤ºæˆ–é»˜è®¤æç¤ºå¼€å§‹
        if agent_config and agent_config.get("system_prompt"):
            system_content = agent_config["system_prompt"].strip()
        else:
            system_content = default_system_content

        now = datetime.datetime.now(datetime.timezone.utc)
        datetime_info = f"\n\n=== å½“å‰æ—¥æœŸ/æ—¶é—´ä¿¡æ¯ ===\n"
        datetime_info += f"ä»Šå¤©çš„æ—¥æœŸ: {now.strftime('%A, %B %d, %Y')}\n"
        datetime_info += f"å½“å‰å¹´ä»½: {now.strftime('%Y')}\n"
        datetime_info += f"å½“å‰æœˆä»½: {now.strftime('%B')}\n"
        datetime_info += f"å½“å‰æ—¥æœŸ: {now.strftime('%A')}\n"
        datetime_info += (
            "å°†æ­¤ä¿¡æ¯ç”¨äºä»»ä½•æ—¶é—´æ•æ„Ÿçš„ä»»åŠ¡ã€ç ”ç©¶ï¼Œæˆ–éœ€è¦å½“å‰æ—¥æœŸ/æ—¶é—´ä¸Šä¸‹æ–‡æ—¶ã€‚\n"
        )

        system_content += datetime_info

        # å¦‚æœæä¾›äº†user_idï¼Œæ·»åŠ ç”¨æˆ·åœ°åŒºä¸Šä¸‹æ–‡
        if user_id:
            try:
                from core.utils.user_locale import (
                    get_locale_context_prompt,
                    get_user_locale,
                )

                locale = await get_user_locale(user_id)
                locale_prompt = get_locale_context_prompt(locale)
                system_content += f"\n\n{locale_prompt}\n"
                logger.debug(
                    f"ä¸ºç”¨æˆ· {user_id} æ·»åŠ äº†åœ°åŒºä¸Šä¸‹æ–‡ ({locale}) åˆ°ç³»ç»Ÿæç¤ºä¸­"
                )
            except Exception as e:
                logger.warning(f"å‘ç³»ç»Ÿæç¤ºæ·»åŠ åœ°åŒºä¸Šä¸‹æ–‡å¤±è´¥: {e}")

        system_message = {"role": "system", "content": system_content}
        return system_message


class AgentRunner:
    def __init__(self, config: AgentConfig):
        self.config = config

    async def setup(self):
        self.thread_manager = ThreadManager(agent_config=self.config.agent_config)

        with get_db() as db:
            response = (
                db.query(Thread.account_id)
                .filter(Thread.thread_id == self.config.thread_id)
                .first()
            )

        if not response:
            raise ValueError(f"æœªæ‰¾åˆ°çº¿ç¨‹ {self.config.thread_id}")

        self.account_id = response.account_id

        if not self.account_id:
            raise ValueError(f"çº¿ç¨‹ {self.config.thread_id} æ²¡æœ‰å…³è”çš„è´¦æˆ·")

        with get_db() as db:
            project = (
                db.query(Project)
                .filter(Project.project_id == self.config.project_id)
                .first()
            )

        if not project:
            raise ValueError(f"æœªæ‰¾åˆ°é¡¹ç›® {self.config.project_id}")

        project_data = ProjectModel.model_validate(project)
        sandbox_info = project_data.sandbox
        if not sandbox_info.get("id"):
            logger.debug(
                f"æœªæ‰¾åˆ°é¡¹ç›® {self.config.project_id} çš„sandboxï¼›å°†åœ¨éœ€è¦æ—¶å»¶è¿Ÿåˆ›å»º"
            )

    async def run(
        self, cancellation_event: Optional[asyncio.Event] = None
    ) -> AsyncGenerator[Dict[str, Any], None]:
        await self.setup()

        system_message = await PromptManager.build_system_prompt(
            self.config.model_name,
            self.config.agent_config,
            self.config.thread_id,
            # tool_registry=self.thread_manager.tool_registry,
            user_id=self.account_id,
        )
        logger.info(
            f"ğŸ“ ç³»ç»Ÿæ¶ˆæ¯æ„å»ºå®Œæˆ: {len(str(system_message.get('content', '')))} å­—ç¬¦"
        )
        logger.debug(f"æ”¶åˆ° model_name: {self.config.model_name}")
        iteration_count = 0
        continue_execution = True

        with get_db() as db:
            latest_user_message = (
                db.query(Message)
                .filter(Message.thread_id == self.config.thread_id)
                .filter(Message.type == "user")
                .order_by(Message.created_at.desc())
                .first()
            )

        latest_user_message_content = None
        if latest_user_message:
            data = latest_user_message.content
            if isinstance(data, str):
                data = json.loads(data)
            # æå–å†…å®¹ç”¨äºå¿«é€Ÿè·¯å¾„ä¼˜åŒ–
            latest_user_message_content = (
                data.get("content") if isinstance(data, dict) else str(data)
            )

        while continue_execution and iteration_count < self.config.max_iterations:
            iteration_count += 1

            with get_db() as db:
                latest_message = (
                    db.query(Message)
                    .filter(Message.thread_id == self.config.thread_id)
                    .filter(Message.type.in_(["assistant", "tool", "user"]))
                    .order_by(Message.created_at.desc())
                    .first()
                )

            if latest_message:
                message_type = latest_message.type
                if message_type == "assistant":
                    continue_execution = False
                    break

            temporary_message = None
            # é»˜è®¤ä¸è®¾ç½®max_tokens - è®©LiteLLMå’Œæä¾›å•†å¤„ç†è‡ªå·±çš„é»˜è®¤å€¼
            max_tokens = None
            logger.debug(f"max_tokens: {max_tokens} (ä½¿ç”¨æä¾›å•†é»˜è®¤å€¼)")
            try:
                logger.debug(f"å¼€å§‹ä¸º {self.config.thread_id} æ‰§è¡Œçº¿ç¨‹")
                response = await self.thread_manager.run_thread(
                    thread_id=self.config.thread_id,
                    system_prompt=system_message,
                    stream=True,
                    llm_model=self.config.model_name,
                    llm_temperature=0,
                    llm_max_tokens=max_tokens,
                    tool_choice="auto",
                    max_xml_tool_calls=1,
                    temporary_message=temporary_message,
                    latest_user_message_content=latest_user_message_content,
                    processor_config=ProcessorConfig(
                        execute_on_stream=True,
                    ),
                    native_max_auto_continues=self.config.native_max_auto_continues,
                    cancellation_event=cancellation_event,
                )

                last_tool_call = None
                agent_should_terminate = False
                error_detected = False

                try:
                    if hasattr(response, "__aiter__") and not isinstance(
                        response, dict
                    ):
                        async for chunk in response:
                            # æ£€æŸ¥æ¥è‡ªthread_managerçš„é”™è¯¯çŠ¶æ€
                            if (
                                isinstance(chunk, dict)
                                and chunk.get("type") == "status"
                                and chunk.get("status") == "error"
                            ):
                                logger.error(
                                    f"çº¿ç¨‹æ‰§è¡Œå‡ºé”™: {chunk.get('message', 'æœªçŸ¥é”™è¯¯')}"
                                )
                                error_detected = True
                                yield chunk
                                continue

                            # æ£€æŸ¥æµä¸­çš„é”™è¯¯çŠ¶æ€ï¼ˆæ¶ˆæ¯æ ¼å¼ï¼‰
                            if (
                                isinstance(chunk, dict)
                                and chunk.get("type") == "status"
                            ):
                                try:
                                    content = chunk.get("content", {})
                                    if isinstance(content, str):
                                        content = json.loads(content)

                                    # æ£€æŸ¥é”™è¯¯çŠ¶æ€
                                    if content.get("status_type") == "error":
                                        error_detected = True
                                        yield chunk
                                        continue

                                    # æ£€æŸ¥ä»£ç†ç»ˆæ­¢
                                    metadata = chunk.get("metadata", {})
                                    if isinstance(metadata, str):
                                        metadata = json.loads(metadata)

                                    if metadata.get("agent_should_terminate"):
                                        agent_should_terminate = True

                                        if content.get("function_name"):
                                            last_tool_call = content["function_name"]
                                        elif content.get("xml_tag_name"):
                                            last_tool_call = content["xml_tag_name"]

                                except Exception:
                                    pass

                            # æ£€æŸ¥åŠ©æ‰‹å†…å®¹ä¸­çš„ç»ˆæ­¢XMLå·¥å…·
                            if chunk.get("type") == "assistant" and "content" in chunk:
                                try:
                                    content = chunk.get("content", "{}")
                                    if isinstance(content, str):
                                        assistant_content_json = json.loads(content)
                                    else:
                                        assistant_content_json = content

                                    assistant_text = assistant_content_json.get(
                                        "content", ""
                                    )
                                    if isinstance(assistant_text, str):
                                        if "</ask>" in assistant_text:
                                            last_tool_call = "ask"
                                        elif "</complete>" in assistant_text:
                                            last_tool_call = "complete"

                                except (json.JSONDecodeError, Exception):
                                    pass

                            yield chunk
                    else:
                        # éæµå¼å“åº”æˆ–é”™è¯¯å­—å…¸
                        # logger.debug(f"å“åº”ä¸æ˜¯å¼‚æ­¥å¯è¿­ä»£çš„: {type(response)}")

                        # æ£€æŸ¥æ˜¯å¦æ˜¯é”™è¯¯å­—å…¸
                        if (
                            isinstance(response, dict)
                            and response.get("type") == "status"
                            and response.get("status") == "error"
                        ):
                            logger.error(
                                f"çº¿ç¨‹è¿”å›é”™è¯¯: {response.get('message', 'æœªçŸ¥é”™è¯¯')}"
                            )
                            error_detected = True
                            yield response
                        else:
                            logger.warning(f"æ„å¤–çš„å“åº”ç±»å‹: {type(response)}")
                            error_detected = True

                    if error_detected:
                        break

                    if agent_should_terminate or last_tool_call in ["ask", "complete"]:
                        continue_execution = False

                except Exception as e:
                    # ä½¿ç”¨ErrorProcessorè¿›è¡Œå®‰å…¨é”™è¯¯å¤„ç†
                    processed_error = ErrorProcessor.process_system_error(
                        e, context={"thread_id": self.config.thread_id}
                    )
                    ErrorProcessor.log_error(processed_error)
                    yield processed_error.to_stream_dict()
                    break

            except Exception as e:
                # ä½¿ç”¨ErrorProcessorè¿›è¡Œå®‰å…¨é”™è¯¯è½¬æ¢
                processed_error = ErrorProcessor.process_system_error(
                    e, context={"thread_id": self.config.thread_id}
                )
                ErrorProcessor.log_error(processed_error)
                yield processed_error.to_stream_dict()
                break


async def run_agent(
    thread_id: str,
    project_id: str,
    thread_manager: Optional[ThreadManager] = None,
    native_max_auto_continues: int = 25,
    max_iterations: int = 100,
    model_name: str = "glm-4.6",
    agent_config: Optional[dict] = None,
    cancellation_event: Optional[asyncio.Event] = None,
):
    effective_model = model_name

    config = AgentConfig(
        thread_id=thread_id,
        project_id=project_id,
        native_max_auto_continues=native_max_auto_continues,
        max_iterations=max_iterations,
        model_name=effective_model,
        agent_config=agent_config,
    )

    runner = AgentRunner(config)
    async for chunk in runner.run(cancellation_event=cancellation_event):
        yield chunk
